---
title: 'Midterm Question 2: 2019'
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---
Question 2:  

Record labels often face a decision problem of which musical releases to support
to maximize their financial success. In this question our goal is to predict whether a song will reach a spot in the Top 10 of the Billboard Hot 100 Chart. Taking an analytics approach,
we aim to use information about a song's properties to predict its popularity. The dataset
songs.csv consists of all songs which made it to the Top 10 of the Billboard Hot 100 Chart
from 1990-2010 plus a sample of additional songs that didn't make the Top 10.
The variables included in the dataset either describe the artist or the song, or they are as-
sociated with the following song attributes: time signature, loudness, key, pitch, tempo, and
timbre. Here's a detailed description of the variables:

Here's a detailed description of the variables:

**year**  =    the year the song was released  
**songtitle** = the title of the song  
**artistname** = the name of the artist of the song  
**songID** and **artistID** = identifying variables for the song and artist  
**timesignature** and **timesignature_confidence** = a variable estimating the time signature of the song, and the confidence in the estimate  
**loudness** = a continuous variable indicating the average amplitude of the audio in decibels  
**tempo** and **tempo_confidence** = a variable indicating the estimated beats per minute of the song, and the confidence in the estimate  
**key** and **key_confidence** = a variable with twelve levels indicating the estimated key of the song (C, C#, . . ., B), and the confidence in the estimate  
**energy** = a variable that represents the overall acoustic energy of the song, using a mix of features such as loudness  
**pitch** = a continuous variable that indicates the pitch of the song  
**timbre_0_min, timbre_0_max, timbre_1_min, timbre_1_max, . . . , timbre_11_min**, and **timbre_11_max** = variables that indicate the minimum/maximum values over all segments for each of the twelve values in the timbre vector (resulting in 24 continuous variables)  
**Top10** = a binary variable indicating whether or not the song made it to the Top 10 of the Billboard Hot 100 Chart (1 if it was in the top 10, and 0 if it was not)

Create a dataframe songs.
(a) How many songs appear in the chart by Michael Jackson, and how many of them reached Top 10?
Ans. 18 and 5.
```{r}
songs<-read.csv("songs.csv")
mj <- "Michael Jackson"
sum(songs$artistname == mj)
sum(songs$artistname == mj & songs$Top10)
```
(b) Note that time signature is a discrete variable. What are the values taken by time signature and what are the frequency of occurrences of each value in the dataset?
Ans. 0,1,3,4,5,7. Table below
```{r}
table(songs$timesignature)
```
(c) We would like to predict if a song makes it to the Top 10 chart. The outcome is listed in the variable Top10. Create a training set "SongsTrain" with observations up to and including 2008 releases and a testing set "SongsTest" consisting of 2009 and 2010 song releases.
How many observations (songs) are in the test set?
Ans. 856
```{r}
SongsTrain = subset(songs, year <= 2008)
SongsTest = subset(songs, year >= 2009)
nrow(SongsTest)
```
(d) Now we remove the variables not used for prediction: "year", "songtitle", "artistname", "songID" or "artistID". Define
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")

Type the following:
SongsTrain = SongsTrain[ , !(names(SongsTrain) %in% nonvars) ]
SongsTest = SongsTest[ , !(names(SongsTest) %in% nonvars) ]
Now use the glm function to predict Top10 using all other available variables (use the training set). Call this Model 1. What is the value of  Akaike's Information Criterion? Choose the correct family for using logistic regression.
Ans. 4538.12
```{r}
nonvars = c("year", "songtitle", "artistname", "songID", "artistID")
SongsTrain = SongsTrain[, !(names(SongsTrain) %in% nonvars)]
SongsTest = SongsTest[, !(names(SongsTest) %in% nonvars)]

SongsLog1 = glm(Top10 ~ ., data = SongsTrain, family = binomial)
SongsLog1$aic
summary(SongsLog1)
```
(e)  Songs with heavy instrumentation are supposed to be  louder (higher "loudness" value). Sometimes they also tend to be more energetic (high "energy" values). From the coefficients obtained for , which one of the following would you think is correct:
  (i) Mainstream listeners prefer songs heavy instrumentation and high energy.  
  (ii) Mainstream listeners prefer songs with light instrumentation and high energy.
  (iii) Mainstream listeners prefer songs with heavy instrumentation and low energy.
  (iv) Mainstream listeners prefer songs with light instrumentation and low energy.
Ans. (iii) since coefficient for loudness is positive and for energy is negative.

(f) Find the correlation between loudness and energy. You may use the function cor.
Ans. 0.7379225
```{r}
cor(SongsTrain$loudness, SongsTrain$energy)
```
(g) Create a new model with "loudness" removed. You may use Top10~.-loudness in glm. What does your new model suggest?
  (i) Mainstream listeners prefer songs with high energy, contradicting Model 1.
  (ii) Mainstream listeners prefer songs with low energy, as we saw in Model 1.
Ans. (i), energy coefficient is now positive. this is due to multicollinearity.
```{r}
SongsLog2 = glm(Top10 ~ . - loudness, data = SongsTrain, family = binomial)
summary(SongsLog2)
```
(h) Create Model 3 like Model 1 but just removing "energy" now. What is the AIC of this model? 
Ans. 4560.535
```{r}
SongsLog3 = glm(Top10 ~ . - energy, data=SongsTrain, family=binomial)
SongsLog3$aic
```
(i) Now make predictions on your test set SongsTest using Model 3. Compute the accuracy of the model using a threshold value of 0.40. Also find the baseline accuracy (this is the accuracy if we pick the most frequent outcome as our prediction).
Ans. Accuracy = 0.8679907; Base accuracy = 0.864486.
Notes:
- baseline accuracy: (number of majority class) / (total predictions)
- accuracy: (total correct predictions) / (total predictions)
- sensitivity/recall: (true positives) / (total positives)
- specificity: (true negatives) / (total negatives)
- precision: (true positives) / (total predicted positives)
```{r}
testPredict <- predict(SongsLog3, newdata = SongsTest, type = "response")
Pred1 <- table(testPredict >= 0.4, SongsTest$Top10)
Accuracy1 <- (Pred1[1, 1] + Pred1[2, 2]) / (sum(Pred1))
Baseaccuracy <- (Pred1[1, 1] + Pred1[2, 1]) / (sum(Pred1))
Pred1
Accuracy1
Baseaccuracy
```
(j) What are the sensitivity and specificity values you obtain using Model 3 on the SongsTest
data with threshold 0.40?
Ans. Specificity = 0.9540541, Sensitivity = 0.3189655.
```{r}
Specif1 <- Pred1[1, 1] / sum(Pred1[, 1])
Sens1 <-   Pred1[2, 2] / sum(Pred1[, 2])
Specif1
Sens1
```
(k) Use the command performance in the ROCR package to find the AUC value for Model 3
on the test data.
Ans. 0.826829
```{r}
library(ROCR)
ROCRpred <- prediction(testPredict, SongsTest$Top10)
p <- performance(ROCRpred, measure = "auc")
p@y.values
```
(l) Let us check the robustness of your findings by trying an alternative to logistic regression, namely, probit regression where the equation to be estimated is given $Pr(Y = 1) = \Phi(\beta_0 + \beta_1x_1 + ... + \beta_px_p)$ where $\Phi$ is the standard normal cumulative distribution function. Build this model using the data set SongsTrain, which we call Model 4 with only the statistically significant predictors (at level 0.05) that you identified while building Model 3 on SongsTrain. Hint: You can fit the model by using glm by modifying the family argument with family = binomial(link="probit"). Write down the accuracy for the probit fit with a threshold of 0.40 on the test data set SongsTest.
Ans. Accuracy = 0.8679907
```{r}
SongsLog4 = glm(Top10 ~ . -energy-timesignature-tempo-key-timbre_1_max-timbre_2_min-timbre_2_max-timbre_3_min-timbre_5_max-timbre_6_max-timbre_8_min-timbre_8_max-timbre_9_min-timbre_9_max, data=SongsTrain, family=binomial(link="probit"))
summary(SongsLog4)

testPredict2 = predict(SongsLog4, newdata=SongsTest, type="response")
Pred2<- table(testPredict2 > 0.4,SongsTest$Top10)
Pred2
Accuracy2<- (Pred2[1,1]+Pred2[2,2])/(sum(Pred2))
Accuracy2
```
(m) What are the sensitivity and specificity values you obtain using Model 4 on the SongsTest
data with threshold 0.40?
Ans. Specificity = 0.9581081, Sensitivity = 0.2931034.
```{r}
Specif2 <- Pred2[1, 1] / sum(Pred2[, 1])
Sens2 <-   Pred2[2, 2] / sum(Pred2[, 2])
Specif2
Sens2
```
(n) From your findings in parts (h)-(l), would you prefer Model 3 or Model 4 as your choice,
or, are they indistinguishable? Give a short justification.
Ans. The probit model seems to perform slightly better for sensitivity; a little worse for specificity. But both model seem reasonably comparable.
